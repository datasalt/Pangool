---
layout: user_guide
title: Pangool - User guide - Reduce-side Joins
---
<div class="hero-unit">
	<h1>Pangool User Guide</h1>
</div>

<h1>Reduce-side Joins</h1>

<p>
One of the most interesting features of Pangool is its inherent reduce-side join capabilities.
</p>

<p>
 In this section we’ll comment one of the examples that can be found in the 
 <a href="https://github.com/datasalt/pangool/tree/master/examples">examples</a> sub-project of Pangool
  (<a href="https://github.com/datasalt/pangool/tree/master/examples/src/main/java/com/datasalt/pangool/examples/urlresolution/UrlResolution.java">the URL resolution example</a>)
   to illustrate how easy it is to perform arbitrary reduce-side joins with Pangool.
</p>

<p>
 We have one file with URL registers: [<code>url</code>, <code>timestamp</code>, <code>ip</code>] 
 and another file with canonical URL mappings: [<code>url</code>, <code>canonicalUrl</code>].
 We want to output the URL registers file and have the url be substituted with the canonical 
 one according to the mapping file. In other words, we want the output to be like: [<code>canonicalUrl</code>, <code>timestamp</code>, <code>ip</code>]
</p>

<p>
For that, we need to join the URL registers file with the URL mappings one. 
We need to join them by the common field <code>url</code>. Using a reduce-side join, we 
could store the “canonicalUrl” for each <code>url</code> group and apply the substitution 
to each of the URL registers records associated with that <code>url</code>. 
</p>
<p>
To make the join totally scalable, we need to receive the <code>canonicalUrl</code> first 
in each reduce group so that we only need to stream through the URL registers afterwards.
</p>

<p>
We’ll configure a Pangool Job to accept two inputs and two intermediate schemas. Let’s start by checking each of the Mapper implementations:
</p>

<pre class="prettyprint" id="java">
 public static class UrlProcessor extends TupleMapper&lt;LongWritable, Text&gt; {
   private Tuple tuple;

   public void map(LongWritable key, Text value, TupleMRContext context, Collector collector)
     throws IOException, InterruptedException {

     if(tuple == null) {
       tuple = new Tuple(context.getTupleMRConfig().getIntermediateSchema("urlRegister"));
     }
     String[] fields = value.toString().split("\t");
     tuple.set("url", fields[0]);
     tuple.set("timestamp", Long.parseLong(fields[1]));
     tuple.set("ip", fields[2]);
     collector.write(tuple);
   }
 }
</pre>

<p>
This Mapper is quite simple. It just parses the input URL registers file and emits a tuple
with the needed data. It uses the <code>context.getTupleMRConfig().getIntermediateSchema()</code> to grab 
the intermediate schema that was configured.
</p>

<pre class="prettyprint" id="java">
 public static class UrlMapProcessor extends TupleMapper&lt;LongWritable, Text&gt; {

   private Tuple tuple;

   public void map(LongWritable key, Text value, TupleMRContext context, Collector collector)
     throws IOException, InterruptedException {
     if(tuple == null) {
       tuple = new Tuple(context.getTupleMRConfig().getIntermediateSchema("urlMap"));
     }

     String[] fields = value.toString().split("\t");
     tuple.set("url", fields[0]);
     tuple.set("canonicalUrl", fields[1]);
     collector.write(tuple);
   }
 }
</pre>

<p>
Same thing for this one: just parsing and emitting a Tuple. 
Let’s now check to see the Reducer that performs the join:
</p>

<pre class="prettyprint" id="java">
 public static class Handler extends TupleReducer&lt;Text, NullWritable&gt; {

   private Text result;

   public void reduce(ITuple group, Iterable&lt;ITuple&gt; tuples, TupleMRContext context, Collector collector)
     throws IOException, InterruptedException, TupleMRException {
     if (result == null) {
       result = new Text();
     }
     String cannonicalUrl = null;
     for(ITuple tuple : tuples) {
       if("urlMap".equals(tuple.getSchema().getName())) {
         cannonicalUrl = tuple.get("canonicalUrl").toString();
       } else {
         result.set(cannonicalUrl + "\t" + tuple.get("timestamp") + "\t" + tuple.get("ip"));
         collector.write(result, NullWritable.get());
       }
     }
   }
 }
</pre>

<p>
Let’s comment on this specific part of the code:
</p>

<pre class="prettyprint" id="java">
 for(ITuple tuple : tuples) {
   if("urlMap".equals(tuple.getSchema().getName())) {
     cannonicalUrl = tuple.get("canonicalUrl").toString();
   } else {
     ...
     collector.write(result, NullWritable.get());
   }
 }
</pre>

<p>
What happens is that we are iterating over each of the Tuples associated with the same 
<code>url</code> group, but we are keeping a state variable in case that the Tuple belongs 
to one of the schemas (the one that processed URL mapping registers).
Then, we use this state variable for emitting each of the URL registers.
 Note how we are assuming that the URL mapping comes always before the URL registers.
 In other words, there is a specific source sort within the records of the joined Tuple list. 
 We’ll see this in greater detail when we configure the job.
</p>

<p>
Let’s now check the job configuration:
</p>

<pre class="prettyprint" id="java">
 TupleMRBuilder builder = new TupleMRBuilder(conf,"Pangool Url Resolution");
 builder.addIntermediateSchema(new Schema("urlMap", urlMapFields));
 builder.addIntermediateSchema(new Schema("urlRegister", urlRegisterFields));
 builder.setFieldAliases("urlMap",new Aliases().add("url","nonCanonicalUrl"));
 builder.setGroupByFields("url");
 
 ...
</pre>

<div class="alert alert-info">
<p><b>Note:</b>
The specified fields in <code>setGroupByFields</code> must be present in all the intermediate 
schemas defined.<br>If the field we want to group by is named differently among the schemas
then we must declare an alias for it, using <code><a href="http://pangool.net/apidocs/com/datasalt/pangool/tuplemr/TupleMRConfigBuilder.html#setFieldAliases(java.lang.String, com.datasalt.pangool.tuplemr.Aliases)">builder.setFieldAliases()</a></code> and use
that alias to group by, as is shown above.<br/>
</p>
</div>
<p>
And that’s about it! We have just defined two schemas and defined the group key. Note that even <code>url</code> 
field is not present in schema <code>urlRegister</code> ,the alias <code>url</code> refers to <code>nonCanonicalUrl</code>, so actually tuples are grouped by <code>nonCanonicalUrl</code>.<br>
by default, Pangool will sort by the group by fields and will peform intersource sorting based on the order in which we defined the sources.<br/> 
In this case, for each group, the URL mapping will come first - and that’s why the code above works. 
</p>

<p>
In order to configure a special sorting for the join, you’ll need to use <code>addSchemaOrder()</code>
as needed depending on which place you want to put the <i>inter-source</i> ordering in your custom sorting.
</p>
<p>
More info in <a href="group_and_sort.html">Group-By & Sort-By</a> section.
</p>
<p><a class="btn btn-primary btn-large" href="map_only_jobs.html">Next: Map-only Jobs &raquo;</a></p>